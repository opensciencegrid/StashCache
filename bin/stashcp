#!/usr/bin/env python

import optparse
import sys
import subprocess
import time
import re
import os
import json
import multiprocessing
import urllib2
import random
import shutil

import logging
from urlparse import urlparse



TIMEOUT = 300
DIFF = TIMEOUT * 10


def doStashCpSingle(sourceFile, destination, cache, debug=False):

    logging.debug("Checking size of file.")
    (xrdfs_stdout, xrdfs_stderr) = subprocess.Popen(["xrdfs", "root://stash.osgconnect.net", "stat", sourceFile], stdout=subprocess.PIPE).communicate()
    xrdcp_version = subprocess.Popen(['echo $(xrdcp -V 2>&1)'], stdout=subprocess.PIPE, shell=True).communicate()[0][:-1]
    try:
        fileSize = int(re.findall(r"Size:   \d+", xrdfs_stdout)[0].split(":   ")[1])
    except Exception as e:
        sys.stderr.write("Unable to find size of file\n")
        print str(xrdfs_stdout)
        sys.stderr.write(str(xrdfs_stderr))
        print str(e)
        return 1
    logging.debug("Size of the file %s is %s", sourceFile, str(fileSize))
    #cache=get_best_stashcache()
    logging.debug("Using Cache %s", cache)
    
    sitename = os.environ.setdefault("OSG_SITE_NAME", "siteNotFound")
    
    # Fill out the payload as much as possible
    filename = destination + '/' + sourceFile.split('/')[-1]
    payload = {}
    payload['xrdcp_version'] = xrdcp_version
    payload['filesize'] = fileSize
    payload['filename'] = sourceFile
    payload['sitename'] = sitename
    
    # Calculate the starting time
    start1 = int(time.time()*1000)
    
    # First, check if the file is available in CVMFS
    # Really, we don't need to check for close caches before this, but oh well
    if sourceFile[0] == '/':
        cvmfs_file = os.path.join("/cvmfs/stash.osgstorage.org/", sourceFile[1:])
    else:
        cvmfs_file = os.path.join("/cvmfs/stash.osgstorage.org/", sourceFile)
    logging.debug("Checking if the CVMFS file exists: %s", cvmfs_file)
    if os.path.exists(cvmfs_file):
        try:
            shutil.copy(cvmfs_file, destination)
            logging.debug("Succesfully copied file from CVMFS!")
            end1 = int(time.time()*1000)
            dlSz=os.stat(destination).st_size
            dltime=end1-start1
            destSpace=1
            status = 'Success'
            payload['timestamp']=end1
            payload['host']="CVMFS"
            payload['download_size']=dlSz
            payload['download_time']=dltime
            payload['destination_space']=destSpace
            payload['status']=status
            payload['tries']=1
            payload['start1']=start1
            payload['end1']=end1
            payload['cache']="CVMFS"
            es_send(payload)
                
            return 0
            
        except IOError, e:
            logging.error("Unable to copy with CVMFS, even though file exists: %s", str(e))
    
    else:
        logging.debug("CVMFS File does not exist")
        
    end1=int(time.time()*1000)
    payload['end1']=end1
    payload['start1']=start1
    
    start2 = int(time.time()*1000)
    
    xrd_exit=timed_transfer(filename=sourceFile, debug=debug, cache=cache, destination=destination)
    
    end2=int(time.time()*1000)
    if os.path.exists(destination):
        dlSz=os.stat(destination).st_size
    destSpace=1

    payload['xrdexit1']=xrd_exit
    payload['start2']=start2
    payload['end2']=end2
    
    if xrd_exit=='0': #worked first try
        logging.debug("Transfer success using %s", cache)
        dltime=end2-start2
        status = 'Success'
        tries=2

        payload['download_size']=dlSz
        payload['download_time']=dltime
        payload['sitename']=sitename
        payload['destination_space']=destSpace
        payload['status']=status
        payload['tries']=tries
        payload['cache']=cache
        es_send(payload)

    else: #pull from origin
        logging.warning("XrdCP from cache failed on %s, pulling from origin", cache)
        cache="root://stash.osgconnect.net"
        start3 = int(time.time()*1000)
        xrd_exit=timed_transfer(filename=sourceFile, debug=debug, cache=cache, destination=destination)
        end3=int(time.time()*1000)
        if os.path.exists(destination):
            dlSz=os.stat(destination).st_size
        dltime=end3-start3
        if xrd_exit=='0':
            logging.info("Trunk Success")
            status = 'Trunk Sucess'
            tries=3
        else:
            logging.error("stashcp failed after 3 attempts")
            status = 'Timeout'
            tries = 3
        payload['download_size']=dlSz
        payload['download_time']=dltime
        payload['destination_space']=destSpace
        payload['status']=status
        payload['xrdexit2']=xrd_exit
        payload['tries']=tries
        payload['start3']=start3
        payload['end3']=end3
        payload['cache']=cache
        es_send(payload)
        if xrd_exit == '0':
            return 0
        else:
            return 1
    return 0


def dostashcpdirectory(sourceDir, destination, cache, debug=False):
    sourceItems = subprocess.Popen(["xrdfs", "root://stash.osgconnect.net", "ls", sourceDir], stdout=subprocess.PIPE).communicate()[0].split()
    for remote_file in sourceItems:
        command2 = 'xrdfs root://stash.osgconnect.net stat '+ remote_file + ' | grep "IsDir" | wc -l'
        isdir=subprocess.Popen([command2],stdout=subprocess.PIPE,shell=True).communicate()[0].split()[0]
        if isdir!='0':
            result = dostashcpdirectory(remote_file, destination, cache, debug)
        else:
            result = doStashCpSingle(remote_file,destination, cache, debug)
        # Stop transfers if something fails
        if result != 0:
            return result


def es_send(payload):
    
    # Calculate the curernt timestamp
    payload['timestamp'] = int(time.time()*1000)
    payload['host'] = payload['cache']
    
    def _es_send(payload):
        data = payload
        data=json.dumps(data)
        try:
            url = "http://uct2-collectd.mwt2.org:9951"
            req = urllib2.Request(url, data=data, headers={'Content-Type': 'application/json'})
            f = urllib2.urlopen(req)
            f.read()
            f.close()
        except urllib2.URLError, e:
            logging.warning("Error posting to ES: %s", str(e))
    
    p = multiprocessing.Process(target=_es_send, name="_es_send", args=(payload,))
    p.start()
    p.join(5)
    p.terminate()
    


def timed_transfer(filename, cache, destination, debug=False):
    """
    Transfer the filename from the cache to the destination using xrdcp
    """
    
    
    # All these values can be found on the xrdcp man page
    os.environ.setdefault("XRD_REQUESTTIMEOUT", "30")   # How long to wait for a read request (s)
    os.environ.setdefault("XRD_CPCHUNKSIZE", "8388608") # Size of each read request (8MB)
    os.environ.setdefault("XRD_TIMEOUTRESOLUTION", "5") # How often to check the timeouts
    os.environ.setdefault("XRD_CONNECTIONWINDOW", "30") # How long to wait for the initial TCP connection
    os.environ.setdefault("XRD_CONNECTIONRETRY", "2")   # How many time should we retry the TCP connection
    os.environ.setdefault("XRD_STREAMTIMEOUT", "30")    # How long to wait for TCP activity
    
    filepath=cache+":1094//"+ filename
    if debug:
        command="xrdcp -d 2 --nopbar -f " + filepath + " " + destination
    else:
        command="xrdcp -s -f " + filepath + " " + destination
        
    filename="./"+filename.split("/")[-1]
    if os.path.isfile(filename):
        os.remove(filename)
    xrdcp=subprocess.Popen([command ],shell=True,stdout=subprocess.PIPE)
    
    xrdcp.communicate()
    xrd_exit=xrdcp.returncode

    return str(xrd_exit)


def get_best_stashcache():
    
    # First, check for caches.json file in this file's directory:
    dir_path = os.path.dirname(os.path.realpath(__file__))
    cache_file = os.path.join(dir_path, 'caches.json')
    if not os.path.isfile(cache_file):
        logging.error("Unable to find caches.json in %s", dir_path)
        return None
    
    # Get all the caches from the json file
    f = open(cache_file, 'r')
    caches_list = json.loads(f.read())
    f.close()
    
    # Get the possible GeoIP sites
    
    # Format the caches for the CVMFS query
    caches_string = ""
    usable_caches = []
    for cache in caches_list:
        if cache['status'] == 0:
            continue
        usable_caches.append(cache)
        parsed_url = urlparse(cache['name'])
        caches_string = "%s,%s" % (caches_string, parsed_url.hostname)
    caches_list = usable_caches
    # Remove the first comma
    caches_string = caches_string[1:]
    
    # Here is a list from the output of the command:
    # attr -qg host_list /cvmfs/oasis.opensciencegrid.org
    geo_ip_sites = "http://cvmfs-s1fnal.opensciencegrid.org:8000/cvmfs/oasis.opensciencegrid.org;http://cvmfs-s1bnl.opensciencegrid.org:8000/cvmfs/oasis.opensciencegrid.org;http://cvmfs-egi.gridpp.rl.ac.uk:8000/cvmfs/oasis.opensciencegrid.org;http://klei.nikhef.nl:8000/cvmfs/oasis.opensciencegrid.org;http://cvmfsrep.grid.sinica.edu.tw:8000/cvmfs/oasis.opensciencegrid.org".split(';')
    
    # Add HCC's, for good measure
    geo_ip_sites.insert(0,"http://hcc-cvmfs.unl.edu:8000/cvmfs/config-osg.opensciencegrid.org")
    
    # Append text before caches string
    append_text = "api/v1.0/geo/@proxy@"
    
    # Randomize the geo ip sites
    random.shuffle(geo_ip_sites)
    found = False
    i = 0
    while found == False and i < len(geo_ip_sites):
        cur_site = geo_ip_sites[i]
        logging.debug("Trying geoip site of: %s", cur_site)
        final_url = "%s/%s/%s" % (cur_site, append_text, caches_string)
        logging.debug("Querying for closest cache: %s", final_url)
        try:
            response = urllib2.urlopen(final_url)
            if response.getcode() == 200:
                logging.debug("Got error code 200 from %s", cur_site)
                found = True
                break
        except urllib2.URLError, e:
            logging.debug("URL error: %s", str(e))
        i+=1
        
    if found == False:
        # Unable to find a geo_ip server to use, return random choice from caches!
        minsite = random.choice(caches_list)
        logging.error("Unable to use Geoip to find closest cache!  Returning random cache %s", minsite)
        return minsite
    else:
    
        # From the response, should respond with something like:
        # 3,1,2
        ordered_list = response.read().strip().split(",")
        logging.debug("Got response %s", str(ordered_list))
        minsite = caches_list[int(ordered_list[0])-1]['name']
        
        logging.debug("Returning closest cache: %s", minsite)
        return minsite


def main():
    usage = "usage: %prog [options] source destination"
    parser = optparse.OptionParser(usage)
    parser.add_option('-d', '--debug', dest='debug', action='store_true', help='debug')
    parser.add_option('-r', dest='recursive', action='store_true', help='recursively copy')
    parser.add_option('--closest', action='store_true')
    parser.add_option('-c', '--cache', dest='cache', help="Cache to use")
    args,opts=parser.parse_args()

    logging.basicConfig(format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',
                       datefmt="%Y-%m-%dT%H:%M:%S%z")
    logger = logging.getLogger()

    
    if args.debug:
        logger.setLevel(logging.DEBUG)
    else:
        logger.setLevel(logging.WARNING)
        
    if args.closest:
        print get_best_stashcache()
        sys.exit(0)

    if len(opts) != 2:
        parser.error('Source and Destination must be specified on command line')
    else:
        source=opts[0]
        destination=opts[1]


    # Check for manually entered cache to use
    if args.cache and len(args.cache) > 0:
        cache = args.cache
    else:
        cache = get_best_stashcache()
    
    if not source.startswith('/'):
        logging.warning("DEPRECIATED: The source path does not begin with a '/', but it is required.  This functionality will be removed in an upcoming release")
        source = "/" + source
    
    
    if not args.recursive:
        result = doStashCpSingle(sourceFile=source, destination=destination, cache=cache, debug=args.debug)
    else:
        result = dostashcpdirectory(sourceDir = source, destination = destination, cache=cache, debug=args.debug)
    # Exit with failure
    sys.exit(result)


if __name__ == "__main__":
    main()
